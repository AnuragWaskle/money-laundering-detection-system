{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79369e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e4e50",
   "metadata": {},
   "source": [
    "Load the New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60f897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Black Money Dataset loaded successfully.\n",
      "Dataset shape: (10000, 14)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../data/raw/Big_Black_Money_Dataset.csv')\n",
    "    print(\"Global Black Money Dataset loaded successfully.\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Big_Black_Money_Dataset.csv' not found. Please download it and place it in 'ml/data/raw/'.\")\n",
    "    df = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de144f9",
   "metadata": {},
   "source": [
    "Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8592f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed and features engineered successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Destination Country</th>\n",
       "      <th>AmountUSD</th>\n",
       "      <th>TaxHavenCountry</th>\n",
       "      <th>RiskScore</th>\n",
       "      <th>isSuspiciousPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.267530e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.965767e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9.416750e+04</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.864201e+05</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6.433784e+05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Destination Country     AmountUSD  TaxHavenCountry  RiskScore  \\\n",
       "0        0                    9  3.267530e+06                4          6   \n",
       "1        1                    5  4.965767e+06                0          9   \n",
       "2        8                    6  9.416750e+04                5          1   \n",
       "3        7                    3  3.864201e+05                3          7   \n",
       "4        5                    9  6.433784e+05                2          1   \n",
       "\n",
       "   isSuspiciousPath  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 3: Preprocessing and Feature Engineering (Corrected for Big_Black_Money_Dataset.csv)\n",
    "\n",
    "if df is not None:\n",
    "    # Select relevant features for tracing using the correct column names\n",
    "    features = [\n",
    "        'Country', \n",
    "        'Destination Country', \n",
    "        'Amount (USD)',\n",
    "        'Tax Haven Country',\n",
    "        'Money Laundering Risk Score'\n",
    "    ]\n",
    "    df_processed = df[features].copy()\n",
    "\n",
    "    # Clean up column names by removing spaces and special characters\n",
    "    df_processed.rename(columns={\n",
    "        'Amount (USD)': 'AmountUSD',\n",
    "        'Tax Haven Country': 'TaxHavenCountry',\n",
    "        'Money Laundering Risk Score': 'RiskScore'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Handle potential missing values\n",
    "    df_processed['TaxHavenCountry'].fillna('None', inplace=True)\n",
    "    df_processed.dropna(subset=['Country', 'Destination Country'], inplace=True)\n",
    "\n",
    "    # --- CORRECTED LOGIC ---\n",
    "    # Create the target label BEFORE encoding the features.\n",
    "    # This is more robust and avoids the \"unseen label\" error.\n",
    "    is_tax_haven = df_processed['TaxHavenCountry'] != 'None'\n",
    "    is_high_risk_score = df_processed['RiskScore'] > 7\n",
    "    df_processed['isSuspiciousPath'] = (is_tax_haven | is_high_risk_score).astype(int)\n",
    "    \n",
    "    # Now, encode the categorical features for the model's input\n",
    "    encoders = {}\n",
    "    for col in ['Country', 'Destination Country', 'TaxHavenCountry']:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        encoders[col] = le\n",
    "    \n",
    "    print(\"Data preprocessed and features engineered successfully.\")\n",
    "    display(df_processed.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71e7ea",
   "metadata": {},
   "source": [
    "Create Transaction Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eabb9063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 9990 sequences of length 10.\n",
      "Shape of X: (9990, 10, 5)\n",
      "Shape of y: (9990,)\n"
     ]
    }
   ],
   "source": [
    "if 'df_processed' in locals():\n",
    "    # Group transactions by the sender to create sequences\n",
    "    # For this example, we'll use an implicit grouping (the whole file is one big trace)\n",
    "    # In a real scenario, you'd group by a case ID or a primary account.\n",
    "    \n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    # We'll treat every 10 transactions as a potential sequence\n",
    "    sequence_length = 10 \n",
    "    for i in range(0, len(df_processed) - sequence_length):\n",
    "        sequence = df_processed.iloc[i:i+sequence_length].drop('isSuspiciousPath', axis=1).values\n",
    "        label = df_processed.iloc[i+sequence_length]['isSuspiciousPath']\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "\n",
    "    X = np.array(sequences)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    print(f\"Created {len(X)} sequences of length {sequence_length}.\")\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235aa44",
   "metadata": {},
   "source": [
    "Scale and Pad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4437bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaled successfully.\n"
     ]
    }
   ],
   "source": [
    "if 'X' in locals():\n",
    "    # Scale the numerical features (amount)\n",
    "    # We reshape to 2D, scale, then reshape back to 3D for the LSTM\n",
    "    scaler = StandardScaler()\n",
    "    X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "    X_scaled = scaler.fit_transform(X_reshaped)\n",
    "    X = X_scaled.reshape(X.shape)\n",
    "\n",
    "    print(\"Data scaled successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f895ebb",
   "metadata": {},
   "source": [
    "Build the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be273b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 10, 5)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 64)            17920     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,369\n",
      "Trainable params: 30,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if 'X' in locals():\n",
    "    model = Sequential([\n",
    "        # The Masking layer ignores any padding we might add\n",
    "        Masking(mask_value=0., input_shape=(X.shape[1], X.shape[2])),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(1, activation='sigmoid') # Output is a single probability (0 to 1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d0d871",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea23045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LSTM trace model...\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 9s 26ms/step - loss: 0.1010 - accuracy: 0.9842 - val_loss: 4.3834e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 3.5317e-04 - accuracy: 1.0000 - val_loss: 2.9047e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 2.5317e-04 - accuracy: 1.0000 - val_loss: 2.2150e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 1.9864e-04 - accuracy: 1.0000 - val_loss: 1.7808e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.6198e-04 - accuracy: 1.0000 - val_loss: 1.4712e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 1.3502e-04 - accuracy: 1.0000 - val_loss: 1.2369e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 1.1426e-04 - accuracy: 1.0000 - val_loss: 1.0534e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 9.7804e-05 - accuracy: 1.0000 - val_loss: 9.0632e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 8.4490e-05 - accuracy: 1.0000 - val_loss: 7.8615e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 7.3532e-05 - accuracy: 1.0000 - val_loss: 6.8649e-05 - val_accuracy: 1.0000\n",
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    print(\"Training the LSTM trace model...\")\n",
    "    history = model.fit(X, y, epochs=10, batch_size=64, validation_split=0.2)\n",
    "    print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007746a",
   "metadata": {},
   "source": [
    "Save the Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a3fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model saved successfully to ../models/lstm_trace_model.h5\n",
      "Scaler saved successfully to ../models/trace_scaler.pkl\n",
      "Encoders saved successfully to ../models/trace_encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    # Save the trained LSTM model\n",
    "    model.save('../models/lstm_trace_model.h5')\n",
    "    print(\"LSTM model saved successfully to ../models/lstm_trace_model.h5\")\n",
    "\n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, '../models/trace_scaler.pkl')\n",
    "    print(\"Scaler saved successfully to ../models/trace_scaler.pkl\")\n",
    "\n",
    "    # Save the label encoders\n",
    "    joblib.dump(encoders, '../models/trace_encoders.pkl')\n",
    "    print(\"Encoders saved successfully to ../models/trace_encoders.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
